<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>UNIG: MODELLING UNITARY 3D GAUSSIANS FOR VIEW-CONSISTENT 3D RECONSTRUCTION</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">UniG: Modelling Unitary 3D Gaussians for View-Consistent 3D Reconstruction</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
                <span class="author-block">
                  <a >Jiamin Wu<sup>1,2*</sup></a>,
                </span>

                <span class="author-block">
                  <a href="https://kenkunliu.github.io/PersonalPage/">Kenkun Liu<sup>3*</sup></a>,
                </span>

                <span class="author-block">
                  <a >Yukai Shi<sup>2</sup></a>,
                </span>

                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=aDf9fpkAAAAJ&hl=en">Xiaoke Jiang<sup>2†</sup></a>,
                </span>

                <span class="author-block">
                  <a >Yuan Yao<sup>1</sup></a>,
                </span>

                <span class="author-block">
                  <a href="https://www.leizhang.org" target="_blank"> Lei Zhang<sup>2</sup></a>
                </span>
            </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">
                      <sup>1</sup>Hong Kong University of Science and Technology, <br>
                      <sup>2</sup>International Digital Economy Academy (IDEA), <br>
                      <sup>3</sup>The Chinese University of Hong Kong (Shenzhen), <br>
                      <sup>3</sup>Tsinghua University
                      <br>arXiv:2410.13195</span>
                    <span class="eql-cntrb">
                      <small><br><sup>*</sup>Equal Contribution</small>
                      <small><br><sup>†</sup>Corresponding Author</small>
                    </span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2410.13195" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="https://arxiv.org/pdf/2410.13195" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/jwubz123/UNIG" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2410.13195" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/teaser.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        3D object reconstruction from sparse-view images
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<hr >
<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In this work, we present UniG, a view-consistent 3D reconstruction and novel view synthesis model that generates a high-fidelity representation of 3D Gaussians from sparse images. Existing 3D Gaussians-based methods usually regress Gaussians per-pixel of each view, create 3D Gaussians per view separately, and merge them through point concatenation. Such a view-independent reconstruction approach often results in a view inconsistency issue, where the predicted positions of the same 3D point from different views may have discrepancies. To address this problem, we develop a DETR (DEtection TRansformer)-like framework, which treats 3D Gaussians as decoder queries and updates their parameters layer by layer by performing multi-view cross-attention (MVDFA) over multiple input images. In this way, multiple views naturally contribute to modeling a unitary representation of 3D Gaussians, thereby making 3D reconstruction more view-consistent. Moreover, as the number of 3D Gaussians used as decoder queries is irrespective of the number of input views, allow an arbitrary number of input images without causing memory explosion. Extensive experiments validate the advantages of our approach, showcasing superior performance over existing methods quantitatively (improving PSNR by 4.2 dB when trained on Objaverse and tested on the GSO benchmark) and qualitatively.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<hr >
<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      
      <h2 class="title" style="text-align: center;">Method</h2>
      <!-- <div id="results-carousel" class="carousel results-carousel"> -->
        <div class="item">
          <!-- Your image here -->
          <img src="static/images/method.png" class="center" height="1000" width="1000" alt="MY ALT TEXT"/>
          <!-- <h2 class="subtitle has-text-centered">
            Unifying Settings 1
          </h2> -->
        </div>
      
        <p>
          Overall Framework: In the coarse stage, 3D Gaussians are produced for each pixel of the sampled random views from the input data. In the refinement stage, 3D Gaussians from the coarse stage serves as the initialization for the refinement network. Multi-view features extracted by the feature extractor serves as keys and values of decoder. Queries are updated by the decoder layer with image features and the positions of the centers of 3D Gaussians. The final 3D Gaussian representation is regressed from the queries. MVDFA: multi-view deformable attention. SESA: spatial efficient self-attention. FFN: feed-forward network.
        </p>
      
      <!-- </div> -->
    </div>
  </div>
</section>
<!-- End image carousel -->


<hr >
<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      
        <h2 class="title" style="text-align: center;">Comparisons</h2>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/comp1.png"  class="center" height="900" width="900" alt="MY ALT TEXT"/>
            <h2 class="subtitle has-text-centered">
              Quantitative results for inputting 4 views on GSO-fixed dataset
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/comp2.png"  class="center" height="700" width="700"  alt="MY ALT TEXT"/>
            <h2 class="subtitle has-text-centered">
              Quantitative results for inputting 4 views on GSO-random dataset
            </h2>
          </div>

          <div class="item">
            <!-- Your image here -->
            <img src="static/images/comp3.png"  class="center" height="500" width="500"  alt="MY ALT TEXT"/>
            <h2 class="subtitle has-text-centered">
              Quantitative results with random number of views as input
            </h2>
          </div>
      
  </div>
</div>
</div>
</section>
<!-- End image carousel -->


<hr >
<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      
      <h2 class="title" style="text-align: center;">Inference Time</h2>
      <!-- <div id="results-carousel" class="carousel results-carousel"> -->
        <div class="item">
          <!-- Your image here -->
          <img src="static/images/time_comp.png" class="center" height="500" width="500" alt="MY ALT TEXT"/>
          <!-- <h2 class="subtitle has-text-centered">
            Unifying Settings 1
          </h2> -->
        </div>
      
        <p>
          Inference time comparison. 3D: 3D Gaussian reconstruction time, render: rendering time, inference: time for one inference including one forward and 32 rendering. Unit in seconds.
        </p>
      
      <!-- </div> -->
    </div>
  </div>
</section>
<!-- End image carousel -->

<!-- References citation -->
<!-- <section class="section" id="References">
    <div class="container is-max-desktop content">
      <h2 class="title">References</h2>
      <pre><code>References: like [1] xxxx</code></pre>
    </div>
</section> -->
<!-- End BibTex citation -->


<hr >
<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{wu2024dig3d,
        title={UniG: Modelling Unitary 3D Gaussians for View-consistent 3D Reconstruction},
        author={Wu, Jiamin and Liu, Kenkun and Shi, Yukai and Jiang, Xiaoke and Yao, Yuan and Zhang, Lei},
        journal={arXiv preprint arXiv:2410.13195},
        year={2024}
      }</code></pre>
    </div>
</section>


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page. This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
